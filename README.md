# TTSè¿è¡ŒåŠè¯„æµ‹å·¥å…·


## ğŸš€ è¿è¡Œæ–¹æ³•

### ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒå’Œæ¨¡å‹å‡†å¤‡

#### 1.1 æ¨¡å‹ä¸‹è½½

1. **RAMPæ¨¡å‹æ£€æŸ¥ç‚¹**ï¼š[ramp_ckpt](https://drive.google.com/file/d/1-l5huyOHWXFtSlGfHnHJVA7dcVS2RSdM/view?usp=sharing) æ”¾ç½®ä½ç½®ï¼š`model_ckpt/ramp_ckpt`

2. **WavLM-largeæ¨¡å‹**ï¼š[wavlm_large_finetune.pth](https://drive.google.com/file/d/1-aE1NfzpRCLxA4GUxX9ITI3F9LlbtEGP/view?usp=sharing) æ”¾ç½®ä½ç½®ï¼šé¡¹ç›®æ ¹ç›®å½•

3. **WavLM-largeåŸºç¡€æ¨¡å‹**ï¼š[wavlm_large.pt](https://huggingface.co/s3prl/converted_ckpts/resolve/main/wavlm_large.pt) æ”¾ç½®ä½ç½®ï¼šé¡¹ç›®æ ¹ç›®å½•

4. **TTSæ¨¡å‹** [CosyVoice2](https://github.com/FunAudioLLM/CosyVoice), [XTTS](https://github.com/coqui-ai/TTS) é€šè¿‡åç»­ä»£ç ä¸‹è½½

5. **ASRæ¨¡å‹** [Whisper-large-v3](https://huggingface.co/openai/whisper-large-v3)ï¼ˆè‹±æ–‡ASRï¼‰ [Paraformer-zh](https://huggingface.co/funasr/paraformer-zh)ï¼ˆä¸­æ–‡ASRï¼‰é¡¹ç›®è‡ªåŠ¨ä¸‹è½½

### ç¬¬äºŒéƒ¨åˆ†ï¼šä¸Šæ¸¸è¿è¡Œï¼ˆTTSè¯­éŸ³åˆæˆï¼‰
#### 2.1 ä¸‹è½½TTSæ¨¡å‹
##### 2.1.1 ä¸‹è½½[CosyVoice2](https://github.com/FunAudioLLM/CosyVoice)ï¼Œæ”¾ç½®åœ¨Upstreamç›®å½•ä¸‹
```bash
cd Upstream

# Clone the repo
git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git
cd CosyVoice
git submodule update --init --recursive

# Create Conda env
conda create -n cosyvoice -y python=3.10
conda activate cosyvoice
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com

# Model download, Put it in Upstream/pretrained_models/CosyVoice2-0.5B
from modelscope import snapshot_download
snapshot_download('iic/CosyVoice2-0.5B', local_dir='pretrained_models/CosyVoice2-0.5B')
```

##### 2.1.2 ä¸‹è½½[XTTS](https://github.com/coqui-ai/TTS)ï¼Œæ”¾ç½®åœ¨Upstreamç›®å½•ä¸‹
```bash
cd Upstream

# Clone the repo
git clone https://github.com/coqui-ai/TTS
cd TTS
pip install -e .[all]

# Create Conda env
conda create -n xtts -y python=3.10
conda activate xtts
pip install TTS

# Model download, Put it in Upstream/pretrained_models/XTTS-v2
cd Upstream/pretrained_models
mkdir XTTS-v2
cd XTTS-v2

wget https://huggingface.co/coqui/XTTS-v2/resolve/main/config.json
wget https://huggingface.co/coqui/XTTS-v2/resolve/main/model.pth

# å›½å†…é•œåƒ
# wget https://hf-mirror.com/coqui/XTTS-v2/resolve/main/model.pth
# wget https://hf-mirror.com/coqui/XTTS-v2/resolve/main/config.json
```

#### 2.2 æ•°æ®è¯´æ˜

è¾“å…¥æ•°æ®å·²åŒ…å«åœ¨ä»“åº“çš„ `InputData/` ç›®å½•ä¸­ï¼š
- `InputData/en/meta.csv`ï¼šè‹±æ–‡å¾…åˆæˆä»»åŠ¡ä¿¡æ¯
- `InputData/zh/meta.csv`ï¼šä¸­æ–‡å¾…åˆæˆä»»åŠ¡ä¿¡æ¯
- `InputData/en/prompt-wavs`ï¼šè‹±æ–‡å‚è€ƒéŸ³é¢‘
- `InputData/zh/prompt-wavs`ï¼šä¸­æ–‡å‚è€ƒéŸ³é¢‘

æ ¼å¼è¯´æ˜ï¼š
```bash
# å¾…åˆæˆéŸ³é¢‘æ–‡æœ¬|å‚è€ƒéŸ³é¢‘è·¯å¾„|å‚è€ƒéŸ³é¢‘æ–‡æœ¬
infer_text|prompt_wav|prompt_text
```

#### 2.3 TTSè¿è¡Œ

ä½¿ç”¨æä¾›çš„è„šæœ¬`run_upstream.sh`ä¸€é”®è¿è¡ŒTTSè¯­éŸ³åˆæˆ:

**CosyVoice2æ¨¡å‹ï¼š**
```bash
bash run_upstream.sh cosyvoice2
```

**XTTSæ¨¡å‹ï¼š**
```bash
bash run_upstream.sh xtts
```

æ‚¨ä¹Ÿå¯ä»¥è‡ªå®šä¹‰æ¨¡å‹ï¼Œå‚è€ƒ`Upstream/run_example.py`å®ç°**exampleæ¨¡å‹ï¼š**
```bash
bash run_upstream.sh example
```
è‡ªå®šä¹‰exampleæ¨¡å‹çš„è¿‡ç¨‹è§[ç¬¬å››éƒ¨åˆ†](#ç¬¬å››éƒ¨åˆ†è‡ªå®šä¹‰ttsæ¥å…¥è¯´æ˜)

**å‚æ•°è¯´æ˜ï¼š**
- æ¨¡å‹åç§°ï¼ˆ`cosyvoice2` æˆ– `xtts`æˆ–è‡ªå®šä¹‰`example`

**è¾“å…¥ç»“æ„ï¼š**
```bash
InputData/
â”œâ”€â”€ en
â”‚   â”œâ”€â”€ meta.csv            # å¾…åˆæˆä»»åŠ¡çš„å…ƒä¿¡æ¯
â”‚   â””â”€â”€ prompt-wavs         # å‚è€ƒéŸ³é¢‘
â””â”€â”€ zh
    â”œâ”€â”€ meta.csv            # å¾…åˆæˆä»»åŠ¡çš„å…ƒä¿¡æ¯
    â””â”€â”€ prompt-wavs         # å‚è€ƒéŸ³é¢‘
```

**è¾“å‡ºç»“æ„ï¼š**
```bash
InputData/
â”œâ”€â”€ en
â”‚   â”œâ”€â”€ meta.csv
â”‚   â”œâ”€â”€ meta_TTSMODEL.csv   # TTSMODELåˆæˆéŸ³é¢‘çš„å…ƒä¿¡æ¯
â”‚   â”œâ”€â”€ prompt-wavs
â”‚   â””â”€â”€ wavs                # åˆæˆçš„éŸ³é¢‘
â””â”€â”€ zh
    â”œâ”€â”€ meta.csv
    â”œâ”€â”€ meta_TTSMODEL.csv   # TTSMODELåˆæˆéŸ³é¢‘çš„å…ƒä¿¡æ¯
    â”œâ”€â”€ prompt-wavs
    â””â”€â”€ wavs                # åˆæˆçš„éŸ³é¢‘
```

meta_TTSMODEL.csv æ ¼å¼è¯´æ˜ï¼š
```bash
# åˆæˆéŸ³é¢‘è·¯å¾„|åˆæˆéŸ³é¢‘æ–‡æœ¬|å‚è€ƒéŸ³é¢‘è·¯å¾„|å‚è€ƒéŸ³é¢‘æ–‡æœ¬
infer_wav|infer_text|prompt_wav|prompt_text

åˆæˆéŸ³é¢‘ï¼ˆinfer_wavï¼‰çš„å‘½åæ–¹å¼ä¸ºï¼šå‚è€ƒéŸ³é¢‘åç§°_TTSMODEL_uuid.wav
```

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¸‹æ¸¸è¿è¡Œï¼ˆæŒ‡æ ‡è®¡ç®—ï¼‰
#### 3.1 é…ç½®ç¯å¢ƒ
å‡†å¤‡å¥½ä½¿ç”¨Python 3.9.12å’Œæ‰€éœ€ä¾èµ–é¡¹çš„ç¯å¢ƒï¼š
```bash
conda create -n eval python=3.9.12
conda activate eval

# Clone and install fairseq
git clone https://github.com/pytorch/fairseq
cd fairseq
pip install --editable ./

# Install additional requirements
pip install -r requirements.txt
```

#### 3.2 ç»¼åˆè¯„ä¼°
ä½¿ç”¨æä¾›çš„è„šæœ¬`run_downstream.sh`ä¸€é”®è¿è¡Œæ‰€æœ‰è¯„ä¼°ï¼š

**CosyVoice2æ¨¡å‹ï¼š**
```bash
bash run_downstream.sh cosyvoice2
```

**XTTSæ¨¡å‹ï¼š**
```bash
bash run_downstream.sh xtts
```

#### 3.3 è¾“å‡ºç»“æœ
è¯„ä¼°å®Œæˆåï¼Œç»“æœå°†è¾“å‡ºåœ¨outputæ–‡ä»¶å¤¹ä¸­ï¼š
```bash
output
â”œâ”€â”€ ramp_TTSMODEL_en.csv
â”œâ”€â”€ ramp_TTSMODEL_zh.csv
â”œâ”€â”€ similarity_TTSMODEL_en.csv
â”œâ”€â”€ similarity_TTSMODEL_zh.csv
â”œâ”€â”€ wer_TTSMODEL_en.csv
â””â”€â”€ wer_TTSMODEL_zh.csv
```

#### 3.4 ç»˜åˆ¶æŒ‡æ ‡é›·è¾¾å›¾
```bash
python run_plot.py
```
ç»“æœå°†è¾“å‡ºåœ¨outputæ–‡ä»¶å¤¹ä¸­ï¼š
```bash
output
â”œâ”€â”€ radar_chart_en.png
â””â”€â”€ radar_chart_zh.png
```

è¾“å‡ºç¤ºä¾‹å›¾ï¼š
<table>
  <tr>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/53f80e2d-f519-4631-8ebd-993dae58b5c4" alt="radar_chart_en"/>
    </td>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/e02fd98a-5ce5-4e4c-b8c2-0ff5a7e0b3ab" alt="radar_chart_zh"/>
    </td>
  </tr>
  <tr>
    <td align="center">radar_chart_en.png</td>
    <td align="center">radar_chart_zh.png</td>
  </tr>
</table>


### ç¬¬å››éƒ¨åˆ†ï¼šè‡ªå®šä¹‰TTSæ¥å…¥è¯´æ˜
1. ä¸‹è½½è‡ªå®šä¹‰TTSé¡¹ç›®åˆ°Upstreamç›®å½•ä¸‹
2. ä¸‹è½½è‡ªå®šä¹‰TTSæ¨¡å‹åˆ°Upstream/pretrained_models/TTSMODELç›®å½•ä¸‹
3. å‚è€ƒ`Upstream/run_example.py`ä¸­çš„TODOï¼Œå®ç°è‡ªå®šä¹‰çš„`Upstream/run_MODEL_NAME.py`
    - å®ç°importå¼•å…¥è‡ªå®šä¹‰TTS
    - åˆ›å»ºè‡ªå®šä¹‰TTSå¯¹è±¡
    - å®Œæˆè‡ªå®šä¹‰TTSæ¨ç†å®ç°
        ```python
        # æ ¹æ®æä¾›çš„å¾…åˆæˆæ–‡æœ¬ï¼ˆinfer_textï¼‰ã€å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ˆprompt_wav_pathï¼‰ã€å‚è€ƒéŸ³é¢‘æ–‡æœ¬ï¼ˆprompt_textï¼‰å’Œè¯­ç§ï¼ˆlangï¼‰å®ç°è‡ªå®šä¹‰TTSçš„éŸ³é¢‘åˆæˆæ¨ç†
        wav = tts.inference(infer_text, prompt_wav_path, prompt_text, lang)
        
        # ä¿å­˜åˆæˆçš„éŸ³é¢‘åˆ°save_wav_path
        torchaudio.save(save_wav_path, wav, sample_rate)
        ```
4. å°†æ¨¡å‹åç§°MODEL_NAMEæ·»åŠ åˆ°run_upstream.shï¼Œè„šæœ¬å°†æ‰§è¡Œ`python Upstream/run_$MODEL_NAME.py --lang "$LANG"`
5. è¿è¡Œ`bash run_upstream.sh MODEL_NAME`å¯åŠ¨ä¸Šæ¸¸TTSåˆæˆä»»åŠ¡