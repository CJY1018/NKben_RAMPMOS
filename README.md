# Nkbench-eval: TTS/VCè¿è¡ŒåŠè‡ªåŠ¨åŒ–è¯„æµ‹å·¥å…·é›†æˆ


## ğŸš€ TTSæ¨¡å—è¿è¡Œæ–¹æ³•

### ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒå’Œæ¨¡å‹å‡†å¤‡

#### 1.1 æ¨¡å‹ä¸‹è½½

1. **RAMPæ¨¡å‹æ£€æŸ¥ç‚¹**ï¼š[ramp_ckpt](https://drive.google.com/file/d/1-l5huyOHWXFtSlGfHnHJVA7dcVS2RSdM/view?usp=sharing) æ”¾ç½®ä½ç½®ï¼š`model_ckpt/ramp_ckpt`

2. **WavLM-largeæ¨¡å‹**ï¼š[wavlm_large_finetune.pth](https://drive.google.com/file/d/1-aE1NfzpRCLxA4GUxX9ITI3F9LlbtEGP/view?usp=sharing) æ”¾ç½®ä½ç½®ï¼šé¡¹ç›®æ ¹ç›®å½•

3. **WavLM-largeåŸºç¡€æ¨¡å‹**ï¼š[wavlm_large.pt](https://huggingface.co/s3prl/converted_ckpts/resolve/main/wavlm_large.pt) æ”¾ç½®ä½ç½®ï¼šé¡¹ç›®æ ¹ç›®å½•

4. **TTSæ¨¡å‹** [CosyVoice2](https://github.com/FunAudioLLM/CosyVoice), [XTTS](https://github.com/coqui-ai/TTS) é€šè¿‡åç»­ä»£ç ä¸‹è½½

5. **ASRæ¨¡å‹** [Whisper-large-v3](https://huggingface.co/openai/whisper-large-v3)ï¼ˆè‹±æ–‡ASRï¼‰ [Paraformer-zh](https://huggingface.co/funasr/paraformer-zh)ï¼ˆä¸­æ–‡ASRï¼‰é¡¹ç›®è‡ªåŠ¨ä¸‹è½½

### ç¬¬äºŒéƒ¨åˆ†ï¼šä¸Šæ¸¸è¿è¡Œï¼ˆTTSè¯­éŸ³åˆæˆï¼‰
#### 2.1 ä¸‹è½½TTSæ¨¡å‹
##### 2.1.1 ä¸‹è½½[CosyVoice2](https://github.com/FunAudioLLM/CosyVoice)ï¼Œæ”¾ç½®åœ¨Upstreamç›®å½•ä¸‹
```bash
cd Upstream

# Clone the repo
git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git
cd CosyVoice
git submodule update --init --recursive

# Create Conda env
conda create -n cosyvoice -y python=3.10
conda activate cosyvoice
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com

# Model download, Put it in Upstream/pretrained_models/CosyVoice2-0.5B
from modelscope import snapshot_download
snapshot_download('iic/CosyVoice2-0.5B', local_dir='pretrained_models/CosyVoice2-0.5B')
```

##### 2.1.2 ä¸‹è½½[XTTS](https://github.com/coqui-ai/TTS)ï¼Œæ”¾ç½®åœ¨Upstreamç›®å½•ä¸‹
```bash
cd Upstream

# Clone the repo
git clone https://github.com/coqui-ai/TTS
cd TTS
pip install -e .[all]

# Create Conda env
conda create -n xtts -y python=3.10
conda activate xtts
pip install TTS

# Model download, Put it in Upstream/pretrained_models/XTTS-v2
cd Upstream/pretrained_models
mkdir XTTS-v2
cd XTTS-v2

wget https://huggingface.co/coqui/XTTS-v2/resolve/main/config.json
wget https://huggingface.co/coqui/XTTS-v2/resolve/main/model.pth
wget https://huggingface.co/coqui/XTTS-v2/resolve/main/vocab.json

# å›½å†…é•œåƒ
# wget https://hf-mirror.com/coqui/XTTS-v2/resolve/main/model.pth
# wget https://hf-mirror.com/coqui/XTTS-v2/resolve/main/config.json
# wget https://hf-mirror.com/coqui/XTTS-v2/resolve/main/vocab.json
```

#### 2.2 æ•°æ®å‡†å¤‡å’Œè¯´æ˜

è¾“å…¥æ•°æ®å·²åŒ…å«åœ¨ä»“åº“çš„ `InputData/` ç›®å½•ä¸­ï¼š
- `InputData/en/meta.csv`ï¼šè‹±æ–‡å¾…åˆæˆä»»åŠ¡ä¿¡æ¯
- `InputData/zh/meta.csv`ï¼šä¸­æ–‡å¾…åˆæˆä»»åŠ¡ä¿¡æ¯
- `InputData/en/prompt-wavs`ï¼šè‹±æ–‡å‚è€ƒéŸ³é¢‘
- `InputData/zh/prompt-wavs`ï¼šä¸­æ–‡å‚è€ƒéŸ³é¢‘

meta.csvæ ¼å¼è¯´æ˜ï¼š
```bash
# å¾…åˆæˆéŸ³é¢‘æ–‡æœ¬|å‚è€ƒéŸ³é¢‘è·¯å¾„|å‚è€ƒéŸ³é¢‘æ–‡æœ¬
infer_text|prompt_wav|prompt_text
```

#### 2.3 TTSè¿è¡Œ

ä½¿ç”¨æä¾›çš„è„šæœ¬`run_upstream.sh`ä¸€é”®è¿è¡ŒTTSè¯­éŸ³åˆæˆ:

**CosyVoice2æ¨¡å‹ï¼š**
```bash
conda activate cosyvoice
bash run_upstream.sh cosyvoice2
```

**XTTSæ¨¡å‹ï¼š**
```bash
conda activate xtts
bash run_upstream.sh xtts
```

æ‚¨ä¹Ÿå¯ä»¥è‡ªå®šä¹‰æ¨¡å‹ï¼Œå‚è€ƒ`Upstream/run_example.py`å®ç°**exampleæ¨¡å‹ï¼š**
```bash
bash run_upstream.sh example
```
è‡ªå®šä¹‰exampleæ¨¡å‹çš„è¿‡ç¨‹è§[ç¬¬å››éƒ¨åˆ†](#ç¬¬å››éƒ¨åˆ†è‡ªå®šä¹‰ttsæ¥å…¥è¯´æ˜)

**å‚æ•°è¯´æ˜ï¼š**
- æ¨¡å‹åç§° (`cosyvoice2` æˆ– `xtts`æˆ–è‡ªå®šä¹‰`example`)

**è¾“å…¥ç»“æ„ï¼š**
```bash
InputData/
â”œâ”€â”€ en
â”‚   â”œâ”€â”€ meta.csv            # å¾…åˆæˆä»»åŠ¡çš„å…ƒä¿¡æ¯
â”‚   â””â”€â”€ prompt-wavs         # å‚è€ƒéŸ³é¢‘
â””â”€â”€ zh
    â”œâ”€â”€ meta.csv            # å¾…åˆæˆä»»åŠ¡çš„å…ƒä¿¡æ¯
    â””â”€â”€ prompt-wavs         # å‚è€ƒéŸ³é¢‘
```

**è¾“å‡ºç»“æ„ï¼š**
```bash
InputData/
â”œâ”€â”€ en
â”‚   â”œâ”€â”€ meta.csv
â”‚   â”œâ”€â”€ meta_TTSMODEL.csv   # TTSMODELåˆæˆéŸ³é¢‘çš„å…ƒä¿¡æ¯
â”‚   â”œâ”€â”€ prompt-wavs
â”‚   â””â”€â”€ wavs                # åˆæˆçš„éŸ³é¢‘
â””â”€â”€ zh
    â”œâ”€â”€ meta.csv
    â”œâ”€â”€ meta_TTSMODEL.csv   # TTSMODELåˆæˆéŸ³é¢‘çš„å…ƒä¿¡æ¯
    â”œâ”€â”€ prompt-wavs
    â””â”€â”€ wavs                # åˆæˆçš„éŸ³é¢‘
```

meta_TTSMODEL.csv æ ¼å¼è¯´æ˜ï¼š
```bash
# åˆæˆéŸ³é¢‘è·¯å¾„|åˆæˆéŸ³é¢‘æ–‡æœ¬|å‚è€ƒéŸ³é¢‘è·¯å¾„|å‚è€ƒéŸ³é¢‘æ–‡æœ¬
infer_wav|infer_text|prompt_wav|prompt_text

åˆæˆéŸ³é¢‘ï¼ˆinfer_wavï¼‰çš„å‘½åæ–¹å¼ä¸ºï¼šå‚è€ƒéŸ³é¢‘åç§°_TTSMODEL_uuid.wav
```

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¸‹æ¸¸è¿è¡Œï¼ˆæŒ‡æ ‡è®¡ç®—ï¼‰
#### 3.1 é…ç½®ç¯å¢ƒ
å‡†å¤‡å¥½ä½¿ç”¨Python 3.9.12å’Œæ‰€éœ€ä¾èµ–é¡¹çš„ç¯å¢ƒï¼š
```bash
conda create -n eval python=3.9.12
conda activate eval

# Clone and install fairseq
git clone https://github.com/pytorch/fairseq
cd fairseq
pip install --editable ./

# Install additional requirements
pip install -r requirements.txt
```

#### 3.2 ç»¼åˆè¯„ä¼°
ä½¿ç”¨æä¾›çš„è„šæœ¬`run_downstream.sh`ä¸€é”®è¿è¡Œæ‰€æœ‰è¯„ä¼°ï¼š

**CosyVoice2æ¨¡å‹ï¼š**
```bash
bash run_downstream.sh cosyvoice2
```

**XTTSæ¨¡å‹ï¼š**
```bash
bash run_downstream.sh xtts
```

#### 3.3 è¾“å‡ºç»“æœ
è¯„ä¼°å®Œæˆåï¼Œç»“æœå°†è¾“å‡ºåœ¨outputæ–‡ä»¶å¤¹ä¸­ï¼š
```bash
output
â”œâ”€â”€ ramp_TTSMODEL_en.csv
â”œâ”€â”€ ramp_TTSMODEL_zh.csv
â”œâ”€â”€ similarity_TTSMODEL_en.csv
â”œâ”€â”€ similarity_TTSMODEL_zh.csv
â”œâ”€â”€ wer_TTSMODEL_en.csv
â””â”€â”€ wer_TTSMODEL_zh.csv
```

#### 3.4 ä¿å­˜å¹³å‡ç»“æœåˆ°æœ¬åœ° & ç»˜åˆ¶æŒ‡æ ‡é›·è¾¾å›¾
å®šä¹‰éœ€è¦è®¡ç®—å¹³å‡ç»“æœçš„æ¨¡å‹
```bash
æ·»åŠ éœ€è¦è®¡ç®—çš„æ¨¡å‹åç§°åˆ°run_plot.pyä¸­çš„model_list
```

æ‰§è¡Œè„šæœ¬
```bash
python run_plot.py
```
ç»“æœå°†è¾“å‡ºåœ¨outputæ–‡ä»¶å¤¹ä¸­ï¼š
```bash
output
â”œâ”€â”€ metric_tts.json
â”œâ”€â”€ radar_chart_en.png
â””â”€â”€ radar_chart_zh.png
```

è¾“å‡ºç¤ºä¾‹å›¾ï¼š
<table>
  <tr>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/53f80e2d-f519-4631-8ebd-993dae58b5c4" alt="radar_chart_en"/>
    </td>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/e02fd98a-5ce5-4e4c-b8c2-0ff5a7e0b3ab" alt="radar_chart_zh"/>
    </td>
  </tr>
  <tr>
    <td align="center">radar_chart_en.png</td>
    <td align="center">radar_chart_zh.png</td>
  </tr>
</table>


### ç¬¬å››éƒ¨åˆ†ï¼šè‡ªå®šä¹‰TTSæ¥å…¥è¯´æ˜
1. æ¨¡å‹å‡†å¤‡ï¼šæä¾›è‡ªå®šä¹‰TTSä»£ç ï¼Œç½®äºåˆ°Upstreamç›®å½•ä¸‹ï¼Œæä¾›è‡ªå®šä¹‰çš„TTSæ¨¡å‹åˆ°Upstream/pretrained_models/TTSMODELç›®å½•ä¸‹ã€‚è‹¥ä¸ºAPIè¯„æµ‹æ–¹å¼å¯è·³è¿‡æ­¤æ­¥ã€‚
2. å‚è€ƒ`Upstream/run_example.py`ä¸­çš„TODOï¼Œå®ç°è‡ªå®šä¹‰çš„`Upstream/run_MODEL_NAME.py`
    - å…³é”®æ¥å£å¦‚ä¸‹
        ```python
        # æ ¹æ®æä¾›çš„å¾…åˆæˆæ–‡æœ¬ï¼ˆinfer_textï¼‰ã€å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ˆprompt_wav_pathï¼‰ã€å‚è€ƒéŸ³é¢‘æ–‡æœ¬ï¼ˆprompt_textï¼‰å’Œè¯­ç§ï¼ˆlangï¼‰å®ç°è‡ªå®šä¹‰TTSçš„éŸ³é¢‘åˆæˆæ¨ç†
        wav = tts.inference(infer_text, prompt_wav_path, prompt_text, lang)
        
        # ä¿å­˜åˆæˆçš„éŸ³é¢‘åˆ°save_wav_path
        torchaudio.save(save_wav_path, wav, sample_rate)
        ```
3. å°†æ¨¡å‹åç§°MODEL_NAMEæ·»åŠ åˆ°run_upstream.shï¼Œè„šæœ¬å°†æ‰§è¡Œ`python Upstream/run_$MODEL_NAME.py --lang "$LANG"`
4. è¿è¡Œ`bash run_upstream.sh MODEL_NAME`å¯åŠ¨ä¸Šæ¸¸TTSåˆæˆä»»åŠ¡

## ğŸš€ VCæ¨¡å—è¿è¡Œæ–¹æ³•
### ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸Šæ¸¸è¿è¡Œï¼ˆVCè¯­éŸ³å‡†æ¢ï¼‰
#### 1.1 ä¸‹è½½[seed-vc](https://github.com/Plachtaa/seed-vc)é¡¹ç›®ï¼Œæ”¾ç½®åœ¨Upstream_VCç›®å½•ä¸‹
```bash
cd Upstream_VC

# Clone the repo
git clone https://github.com/Plachtaa/seed-vc.git
cd seed-vc

# Create Conda env
conda create -n seed-vc python=3.10
conda activate seed-vc
pip install -r requirements.txt
```

#### 1.2 æ•°æ®å‡†å¤‡å’Œè¯´æ˜

è¾“å…¥æ•°æ®å·²åŒ…å«åœ¨ä»“åº“çš„ `InputData_VC/` ç›®å½•ä¸­ï¼š
- `InputData_VC/en/meta.csv`ï¼šè‹±æ–‡å¾…åˆæˆä»»åŠ¡ä¿¡æ¯
- `InputData_CV/zh/meta.csv`ï¼šä¸­æ–‡å¾…åˆæˆä»»åŠ¡ä¿¡æ¯
- `InputData_VC/en/source-wav`ï¼šè‹±æ–‡åŸå§‹éŸ³é¢‘
- `InputData_VC/zh/source-wav`ï¼šä¸­æ–‡åŸå§‹éŸ³é¢‘
- `InputData_VC/en/target-wav`: è‹±æ–‡ç›®æ ‡éŸ³é¢‘
- `InputData_VC/zh/target-wav`: ä¸­æ–‡ç›®æ ‡éŸ³é¢‘

VCå°†æŠŠåŸå§‹éŸ³é¢‘çš„éŸ³è‰²è½¬åŒ–ä¸ºç›®æ ‡éŸ³é¢‘çš„éŸ³è‰²

meta.csvæ ¼å¼è¯´æ˜ï¼š
```bash
# åŸå§‹éŸ³é¢‘è·¯å¾„|ç›®æ ‡éŸ³é¢‘è·¯å¾„
source_wav|target_wav
```

#### 1.3 VCè¿è¡Œ

ä½¿ç”¨æä¾›çš„è„šæœ¬`run_upstream_vc.sh`ä¸€é”®è¿è¡ŒVCè¯­éŸ³è½¬æ¢:

**seed-vcæ¨¡å‹ï¼š**
```bash
conda activate seed-vc
bash run_upstream_vc.sh seed-vc
```
**æ³¨ï¼š** è¿è¡Œseed-vcæ¨ç†æ—¶ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ°Upstream_VC/seed-vc/checkpointsç›®å½•

è‡ªå®šä¹‰exampleæ¨¡å‹çš„è¿‡ç¨‹è§[ç¬¬ä¸‰éƒ¨åˆ†](#ç¬¬ä¸‰éƒ¨åˆ†è‡ªå®šä¹‰vcæ¥å…¥è¯´æ˜)

**å‚æ•°è¯´æ˜ï¼š**
- æ¨¡å‹åç§° (`seed-vc`æˆ–è‡ªå®šä¹‰`example`)
- è‹¥éœ€è¦ä¿®æ”¹VCé»˜è®¤å‚æ•°ï¼Œè¯·è§ï¼šUpstream_VC/run_seed-vc.pyä¸­æ¨¡å‹å‚æ•°è¯´æ˜

**è¾“å…¥ç»“æ„ï¼š**
```bash
InputData_VC/
â”œâ”€â”€ en
â”‚   â”œâ”€â”€ meta.csv            # å¾…è¯­éŸ³è½¬æ¢ä»»åŠ¡çš„å…ƒä¿¡æ¯
â”‚   â””â”€â”€ source-wavs         # åŸå§‹éŸ³é¢‘
â”‚   â””â”€â”€ target-wavs         # ç›®æ ‡éŸ³é¢‘
â””â”€â”€ zh
    â”œâ”€â”€ meta.csv            # å¾…è¯­éŸ³è½¬æ¢ä»»åŠ¡çš„å…ƒä¿¡æ¯
    â”œâ”€â”€ source-wavs         # åŸå§‹éŸ³é¢‘
    â””â”€â”€ target-wavs         # ç›®æ ‡éŸ³é¢‘
```

**è¾“å‡ºç»“æ„ï¼š**
```bash
InputData/
â”œâ”€â”€ en
â”‚   â”œâ”€â”€ meta.csv
â”‚   â”œâ”€â”€ meta_VCMODEL.csv   # VCMODELè¯­éŸ³è½¬æ¢éŸ³é¢‘çš„å…ƒä¿¡æ¯
â”‚   â”œâ”€â”€ prompt-wavs
â”‚   â””â”€â”€ wavs                # è¯­éŸ³è½¬æ¢çš„éŸ³é¢‘
â””â”€â”€ zh
    â”œâ”€â”€ meta.csv
    â”œâ”€â”€ meta_VCMODEL.csv   # VCMODELè¯­éŸ³è½¬æ¢éŸ³é¢‘çš„å…ƒä¿¡æ¯
    â”œâ”€â”€ prompt-wavs
    â””â”€â”€ wavs                # è¯­éŸ³è½¬æ¢çš„éŸ³é¢‘
```

meta_VCMODEL.csv æ ¼å¼è¯´æ˜ï¼š
```bash
# è¯­éŸ³è½¬æ¢éŸ³é¢‘è·¯å¾„|åŸå§‹éŸ³é¢‘è·¯å¾„|ç›®æ ‡éŸ³é¢‘è·¯å¾„
infer_wav|source_wav|target_wav

# argså‚æ•°è¯´æ˜è§Upstream_VC/run_seed-vc.py
è¯­éŸ³è½¬æ¢éŸ³é¢‘ï¼ˆinfer_wavï¼‰çš„å‘½åæ–¹å¼ä¸ºï¼švc_v2_åŸå§‹éŸ³é¢‘åç§°_ç›®æ ‡éŸ³é¢‘åç§°_{args.length_adjust}_{args.diffusion_steps}_{args.similarity_cfg_rate}.wav
```

### ç¬¬äºŒéƒ¨åˆ†ï¼šä¸‹æ¸¸è¿è¡Œï¼ˆæŒ‡æ ‡è®¡ç®—ï¼‰
#### 2.1 é…ç½®ç¯å¢ƒ
å’Œ[TTSä¸‹æ¸¸è¿è¡Œè¯„ä¼°ç¯å¢ƒ](#31-é…ç½®ç¯å¢ƒ)ç›¸åŒï¼Œä»…éœ€æ¿€æ´»ç¯å¢ƒï¼š
```bash
conda activate eval
```

#### 2.2 ç»¼åˆè¯„ä¼°
ç›¸æ¯”äº`TTSæ¨¡å‹`è¾“å‡ºç»“æœwerã€similarityå’Œrampä¸‰ä¸ªç»´åº¦çš„è¯„ä¼°ï¼Œ`VCæ¨¡å‹`è¾“å‡ºç»“æœä»…å¯¹similarityå’Œrampä¸¤ä¸ªç»´åº¦è¿›è¡Œè¯„ä¼°

ä½¿ç”¨æä¾›çš„è„šæœ¬`run_downstream_vc.sh`ä¸€é”®è¿è¡Œæ‰€æœ‰è¯„ä¼°ï¼š

**seed-vcæ¨¡å‹ï¼š**
```bash
bash run_downstream_vc.sh seed-vc
```

#### 2.3 è¾“å‡ºç»“æœ
è¯„ä¼°å®Œæˆåï¼Œç»“æœå°†è¾“å‡ºåœ¨outputæ–‡ä»¶å¤¹ä¸­ï¼š
```bash
output
â”œâ”€â”€ ramp_VCMODEL_en.csv
â”œâ”€â”€ ramp_VCMODEL_zh.csv
â”œâ”€â”€ similarity_VCMODEL_en.csv
â””â”€â”€ similarity_VCMODEL_zh.csv
```

#### 2.4 ä¿å­˜å¹³å‡ç»“æœåˆ°æœ¬åœ°
å®šä¹‰éœ€è¦è®¡ç®—å¹³å‡ç»“æœçš„æ¨¡å‹
```bash
æ·»åŠ éœ€è¦è®¡ç®—çš„æ¨¡å‹åç§°åˆ°run_result_vc.pyä¸­çš„model_list
```

æ‰§è¡Œè„šæœ¬
```bash
python run_result_vc.py
```
ç»“æœå°†è¾“å‡ºåœ¨outputæ–‡ä»¶å¤¹ä¸­ï¼š
```bash
output
â””â”€â”€ metric_vc.json
```

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šè‡ªå®šä¹‰VCæ¥å…¥è¯´æ˜
1. æ¨¡å‹å‡†å¤‡ï¼šæä¾›è‡ªå®šä¹‰VCä»£ç ï¼Œç½®äºåˆ°Upstream_VCç›®å½•ä¸‹ã€‚
2. å‚è€ƒ`Upstream_VC/run_example.py`ä¸­çš„TODOï¼Œå®ç°è‡ªå®šä¹‰çš„`Upstream_VC/run_MODEL_NAME.py`
    - å…³é”®æ¥å£å¦‚ä¸‹
        ```python
        # æ ¹æ®æä¾›çš„åŸå§‹éŸ³é¢‘è·¯å¾„ï¼ˆsource_wav_pathï¼‰ã€ç›®æ ‡éŸ³é¢‘è·¯å¾„ï¼ˆtarget_wav_pathï¼‰å®ç°è‡ªå®šä¹‰VCçš„è¯­éŸ³è½¬æ¢æ¨ç†
        wav = vc_inference(source_wav_path, target_wav_path)
        
        # ä¿å­˜åˆæˆçš„éŸ³é¢‘åˆ°save_wav_path
        torchaudio.save(save_wav_path, wav, sample_rate)
        ```
3. å°†æ¨¡å‹åç§°MODEL_NAMEæ·»åŠ åˆ°run_upstream_vc.shï¼Œè„šæœ¬å°†æ‰§è¡Œ`python Upstream_VC/run_$MODEL_NAME.py --lang "$LANG"`
4. è¿è¡Œ`bash run_upstream_vc.sh MODEL_NAME`å¯åŠ¨ä¸Šæ¸¸VCè¯­éŸ³è½¬æ¢ä»»åŠ¡

## TTMè‡ªåŠ¨è´¨é‡è¯„ä¼°æ¨¡å—è¿è¡Œæ–¹æ³•
### ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒå’Œæ¨¡å‹å‡†å¤‡

#### æ¨¡å‹ä¸‹è½½
- ç‰¹å¾æå–å™¨é‡‡ç”¨[CLAMP3](https://huggingface.co/sander-wood/clamp3/blob/main/weights_clamp3_saas_h_size_768_t_model_FacebookAI_xlm-roberta-base_t_length_128_a_size_768_a_layers_12_a_length_128_s_size_768_s_layers_12_p_size_64_p_length_512.pth)
- è½»é‡MLPä¸‹æ¸¸é¢„æµ‹å¤´æ¨¡å‹[checkpoint]()

#### æ•°æ®å‡†å¤‡
- ä¸Šæ¸¸æ–‡æœ¬è¾“å…¥ä½äº `InputData/ttm/prompt_info.txt`ï¼Œæ¯è¡ŒåŒ…å«ä¸€ä¸ªæ–‡æœ¬æç¤ºè¯çš„ id å’Œæ–‡æœ¬å†…å®¹

éŸ³é¢‘åˆæˆåï¼Œç”Ÿæˆçš„éŸ³é¢‘å°†ä½äº `InputData/ttm/wavs/`


### ç¬¬äºŒéƒ¨åˆ†ï¼šä¸Šæ¸¸è¿è¡Œï¼ˆTTMæ–‡æœ¬ç”ŸæˆéŸ³ä¹ï¼‰

- éŸ³ä¹éŸ³é¢‘åˆæˆ
```bash
bash run_upstream_ttm.sh
```

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¸‹æ¸¸è¿è¡Œï¼ˆåŸºäºMusicEvalçš„è¯„ä¼°æŒ‡æ ‡é¢„æµ‹ï¼‰


è¿è¡Œä¸‹æ¸¸è¯„ä¼°è„šæœ¬`run_downstream_ttm.sh`ï¼Œå®Œæˆï¼š
- æ–‡æœ¬æ‹†åˆ†
- CLAMP3 æ–‡æœ¬/éŸ³é¢‘ global embed æå–
- å®Œæˆä¸‹æ¸¸æ¨ç†ï¼Œä¿å­˜ç»“æœåˆ° `OutputData/ttm_eval/`ä¸‹

```bash
bash run_downstream_ttm.sh
```


## ğŸš€ æ›´æ–°ï¼šæ”¯æŒæ›´å¤šçš„MOS
é™¤RAMPå¤–ï¼Œæˆ‘ä»¬è¿˜é›†æˆäº†æ›´å¤šçš„MOSè¯„æµ‹æ–¹æ³•ï¼š[mos-finetune-ssl](https://github.com/nii-yamagishilab/mos-finetune-ssl)ã€[audiobox-aesthetics](https://github.com/facebookresearch/audiobox-aesthetics)å’Œ[UTMOS](https://github.com/sarulab-speech/UTMOS22)ã€‚

### ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒå‡†å¤‡
ç”±äºè¿™3ä¸ªMOSæ‰€éœ€çš„ç¯å¢ƒä¸ç°æœ‰ç¯å¢ƒéƒ½æœ‰å†²çªï¼Œå»ºè®®éƒ½æ–°å»ºä¸€ä¸ªç¯å¢ƒè¿›è¡Œå®‰è£…
#### 1.1 [mos-finetune-ssl](https://github.com/nii-yamagishilab/mos-finetune-ssl)å®‰è£…
```bash
# åœ¨æ ¹ç›®å½•åˆ›å»ºMOSæ–‡ä»¶å¤¹ï¼Œä»¥ä¸‹3ä¸ªMOSé¡¹ç›®éƒ½æ”¾åœ¨è¯¥æ–‡ä»¶å¤¹ä¸‹
mkdir MOS && cd MOS
git clone https://github.com/nii-yamagishilab/mos-finetune-ssl.git

cd mos-finetune-ssl
conda env create -f environment.yml -n mos

# æ³¨æ„ï¼šå¦‚æœå®‰è£…è¿‡ç¨‹ä¸­æŠ¥é”™ï¼Œå¯èƒ½æ˜¯ä¸¤ä¸ªåŸå› ï¼š
# 1ã€ é¡¹ç›®æ¯”è¾ƒè€ï¼Œcudaç‰ˆæœ¬ä½¿ç”¨11.1ï¼Œå¦‚æœæ‚¨çš„æœºå™¨cudaç‰ˆæœ¬è¾ƒæ–°ï¼Œå¯ä»¥å…ˆç§»é™¤pytorch=1.9.0=py3.7_cuda11.1_cudnn8.0.5_0ã€cudatoolkit=11.1.1=h6406543_8ã€torchvision=0.10.0=py37_cu111ã€torchaudio==0.9.0ï¼Œå…ˆå®‰è£…å…¶ä»–çš„ä¾èµ–ï¼Œæœ€åå†å•ç‹¬å®‰è£…pytorchå’Œtorchvisionå’Œtorchaudioã€‚æˆ–è€…å‚è€ƒæ ¹ç›®å½•ä¸‹çš„environment_mos.ymlå®‰è£…ï¼Œä½¿ç”¨cuda 11.7ç‰ˆæœ¬ï¼Œå®æµ‹åœ¨cuda 12ä¸‹ä¹Ÿå¯ä»¥è¿è¡Œ
# 2ã€ pipçš„ç‰ˆæœ¬è¿‡é«˜ï¼Œæˆ‘ä½¿ç”¨çš„æ˜¯pip 21.1.2ï¼Œä½¿ç”¨pip install pip==21.1.2åˆ‡æ¢

# é…ç½®fairseqï¼Œä½¿ç”¨æ—§ç‰ˆæœ¬fairseq 0.10.2 (https://github.com/facebookresearch/fairseq/archive/refs/tags/v0.10.2.zip)

wget https://github.com/facebookresearch/fairseq/archive/refs/tags/v0.10.2.zip
unzip fairseq-0.10.2.zip # ç¡®ä¿è§£å‹åˆ° MOS/mos-finetune-ssl/fairseq-0.10.2

# ä¸‹è½½æ¨¡å‹ï¼šè¿è¡ŒMOS/mos-finetune-ssl/run_inference.py
python run_inference.py
```

#### 1.2 [audiobox-aesthetics](https://github.com/facebookresearch/audiobox-aesthetics)å®‰è£…
```bash
conda create -n audiobox python=3.10
conda activate audiobox
pip install audiobox_aesthetics

# ä¸‹è½½æ¨¡å‹
# é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œä¸‹è½½çš„ä»£ç åœ¨MOS/audiobox-aesthetics/src/audiobox_aesthetics/utils.pyï¼ŒåŠ è½½çš„ä»£ç åœ¨MOS/audiobox-aesthetics/src/audiobox_aesthetics/infer.pyçš„134è¡Œï¼Œå¯è‡ªè¡Œä¿®æ”¹ä¸ºæœ¬åœ°åŠ è½½
```

#### 1.3 [UTMOS](https://github.com/sarulab-speech/UTMOS22)å®‰è£…
```bash
git clone https://huggingface.co/spaces/sarulab-speech/UTMOS-demo
cd UTMOS-demo

conda create -n UTMOS python=3.8
pip install -r requirements.txt
```

### ç¬¬äºŒéƒ¨åˆ†ï¼šMOSè¯„æµ‹è¿è¡Œ
#### 2.1 æ•°æ®å‡†å¤‡
å’Œ[TTSä¸‹æ¸¸è¿è¡Œè¯„ä¼°æ•°æ®](#32-ç»¼åˆè¯„ä¼°)ç›¸åŒï¼Œä½¿ç”¨`InputData/en/`å’Œ`InputData/zh/`ä¸‹çš„meta_TTSMODEL.csvå’Œwavsæ–‡ä»¶å¤¹

#### 2.2 ç»¼åˆè¯„ä¼°
3ä¸ªæ–°åŠ å…¥çš„MOSè¯„æµ‹å‡å·²æ— ç¼é›†æˆåœ¨`run_downstream.sh`è„šæœ¬ä¸­ï¼Œå’Œä¹‹å‰çš„ä½¿ç”¨æ–¹å¼ä¸å˜ï¼š

è¯„ä¼°TTSæ¨¡å‹çš„æ‰€æœ‰MOSæŒ‡æ ‡ï¼š
```bash
bash run_downstream.sh cosyvoice2
bash run_downstream.sh xtts
```

è¯„ä¼°VCæ¨¡å‹çš„æ‰€æœ‰MOSæŒ‡æ ‡ï¼š
```bash
bash run_downstream_vc.sh seed-vc
```

#### 2.3 è¾“å‡ºç»“æœ
è¯„ä¼°å®Œæˆåï¼Œç»“æœå°†è¾“å‡ºåœ¨outputæ–‡ä»¶å¤¹ä¸­

TTSæ¨¡å‹çš„è¾“å‡ºç»“æœï¼š
```bash
output
â”œâ”€â”€ sslmos_TTSMODEL_en.csv
â”œâ”€â”€ ssltmos_TTSMODEL_zh.csv
â”œâ”€â”€ audiobox_TTSMODEL_en.csv
â”œâ”€â”€ audiobox_TTSMODEL_zh.csv
â”œâ”€â”€ utmos_TTSMODEL_en.csv
â””â”€â”€ utmos_TTSMODEL_zh.csv
```

VCæ¨¡å‹çš„è¾“å‡ºç»“æœï¼š
```bash
output
â”œâ”€â”€ sslmos_VCMODEL_en.csv
â”œâ”€â”€ sslmos_VCMODEL_zh.csv
â”œâ”€â”€ audiobox_VCMODEL_en.csv
â”œâ”€â”€ audiobox_VCMODEL_zh.csv
â”œâ”€â”€ utmos_VCMODEL_en.csv
â””â”€â”€ utmos_VCMODEL_zh.csv
```

#### 2.4 ä¿å­˜å¹³å‡ç»“æœåˆ°æœ¬åœ° & ç»˜åˆ¶æŒ‡æ ‡é›·è¾¾å›¾
å’Œ[TTS/VCä¸‹æ¸¸è¿è¡Œè¯„ä¼°](#34-ä¿å­˜å¹³å‡ç»“æœåˆ°æœ¬åœ°--ç»˜åˆ¶æŒ‡æ ‡é›·è¾¾å›¾)ç›¸åŒï¼Œç›´æ¥è¿è¡Œ`python run_plot.py`æˆ–`python run_result_vc.py`å³å¯ï¼Œç»“æœå°†è¾“å‡ºåœ¨outputæ–‡ä»¶å¤¹ä¸­ï¼š

TTSæ¨¡å‹è¾“å‡ºå¹³å‡ç»“æœå’Œé›·è¾¾å›¾ï¼š
```bash
python run_plot.py
```

VCæ¨¡å‹è¾“å‡ºå¹³å‡ç»“æœï¼š
```bash
python run_result_vc.py
```

æ–°çš„è¾“å‡ºç¤ºä¾‹å›¾ï¼š
<table>
  <tr>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/786b4b05-aefb-4166-bdf6-342118cfc49e" alt="radar_chart_en"/>
    </td>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/9cda96f2-be57-4095-8d32-b014d3f5cbc8" alt="radar_chart_zh"/>
    </td>
  </tr>
  <tr>
    <td align="center">radar_chart_en.png</td>
    <td align="center">radar_chart_zh.png</td>
  </tr>
</table>

## ğŸš€ æ›´æ–°ï¼šæ”¯æŒæ›´æ¢rampçš„datastore_profileï¼Œæ·»åŠ GroundTruth
å¦‚datastore_profile/label.txtä¸­æ‰€ç¤ºï¼Œæˆ‘ä»¬æ–°å¢äº†é’ˆå¯¹CosyVoice2å’ŒXTTSæ¨¡å‹GroundTruth MOSçš„datastore_profileï¼Œå¹¶æ›´æ¢äº†rampé»˜è®¤çš„datastore_profileæ¥æ›´ç²¾ç¡®åœ°è¯„æµ‹TTSæ¨¡å‹åˆæˆéŸ³é¢‘åˆ†å¸ƒçš„MOSã€‚

æ‚¨ä¹Ÿå¯ä»¥æ ¹æ®éœ€è¦æ›´æ¢rampçš„datastore_profileï¼Œå…·ä½“å¦‚ä¸‹ï¼š
1. å‡†å¤‡datastore_profile
```bash
å‚è€ƒdatastore_profile/label.txtä¸­çš„æ ¼å¼ï¼Œå‡†å¤‡å¥½æ‚¨çš„datastore_profile
```

2. è¿è¡Œget_datastore.pyç”Ÿæˆdatastore
```bash
python get_datastore.py --datadir datastore_profile/label.txt --checkpoint model_ckpt/ramp_ckpt --datastore_path datastore_profile
``` 

3. é‡æ–°è¿è¡Œrampè¯„æµ‹
```bashbash
bash run_downstream.sh cosyvoice2
bash run_downstream.sh xtts
```

æ­¤å¤–ï¼Œç°åœ¨æ”¯æŒæ·»åŠ TTSæ¨¡å‹å’ŒVCæ¨¡å‹çš„GroundTruth MOSæ‰“åˆ†ï¼Œæ˜¾ç¤ºåœ¨ç»“æœä¸­ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

1. å‡†å¤‡GroundTruth MOSæ‰“åˆ†æ–‡ä»¶
åœ¨outputæ–‡ä»¶å¤¹ä¸‹ï¼ŒæŒ‰ç…§gt_TTSMODEL_en.csvå’Œgt_TTSMODEL_zh.csvæˆ–gt_VCMODEL_en.csvå’Œgt_VCMODEL_zh.csvçš„æ ¼å¼å‡†å¤‡å¥½GroundTruth MOSæ‰“åˆ†æ–‡ä»¶ï¼Œå‚è€ƒæ ¼å¼å¦‚ä¸‹ï¼š
```csv
filename	gt_mos
10002287-00000094_cosyvoice2_c1d19433-a692-48c5-8a04-2f1cfa4e6bfd.wav	4.3
10002290-00000094_cosyvoice2_fb4cb112-a1c1-43a4-868f-a0c8ed124684.wav	4.1
10002352-00000030_cosyvoice2_e8f8f72d-0523-4432-ba70-a1c40d482442.wav	4.4
```

2. é‡æ–°ç»“æœè¾“å‡º
```bash
# TTSæ¨¡å‹
python run_plot.py

# VCæ¨¡å‹
python run_result_vc.py
```
æ–°çš„è¾“å‡ºç¤ºä¾‹å›¾ï¼š
<table>
  <tr>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/1fc7612b-c6f7-4386-ba82-7ecc566df294" alt="radar_chart_en"/>
    </td>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/b5a9914d-301f-40f9-a7bf-fd64f2487cf9" alt="radar_chart_zh"/>
    </td>
  </tr>
  <tr>
    <td align="center">radar_chart_en.png</td>
    <td align="center">radar_chart_zh.png</td>
  </tr>
</table>

è®¡ç®—MOSæ¨¡å‹ä¸GroundTruth MOSçš„MSE
```bash
python run_compute_mos_mse.py
```

ç»“æœå’Œç»“æœå›¾å°†è¾“å‡ºåœ¨outputæ–‡ä»¶å¤¹ä¸­ï¼š
+ output/mse_tts_bar.json
+ output/bar_group_en.png
+ output/bar_group_zh.png

è¾“å‡ºç¤ºä¾‹å›¾ï¼š
<table>
  <tr>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/0187edb5-09c8-4921-8b41-060d850b929c" alt="radar_chart_en"/>
    </td>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/a178eda7-f5c0-4bbd-b674-1eb201fd90e4" alt="radar_chart_zh"/>
    </td>
  </tr>
  <tr>
    <td align="center">radar_chart_en.png</td>
    <td align="center">radar_chart_zh.png</td>
  </tr>
</table>
